# Dockerfile template for cosmos-curate
#
# The dockerfile is templated so that we can provide different conda env information.
# Docs on docker best practices:
# - https://linuxhandbook.com/dockerize-python-apps/
# - https://uwekorn.com/2021/03/01/deploying-conda-environments-in-docker-how-to-do-it-right.html
# - https://cloud.google.com/architecture/best-practices-for-building-containers

ARG DEBIAN_FRONTEND=noninteractive

FROM nvidia/cuda:12.9.1-devel-ubuntu24.04 AS main

SHELL ["/bin/bash", "-c"]
ENV NVIDIA_DRIVER_CAPABILITIES=compute,video,utility
ENV TZ=America/Los_Angeles
# Get system level packages
RUN apt-get update \
    && apt-get install -y \
    # Needed for opencv
    libsm6 libxext6 \
    # Needed because the certs age out sometimes?
    ca-certificates \
    # Needed for installing pixi \
    wget \
    # Needed for pip install \
    git \
    --option=Dpkg::Options::=--force-confdef \
    && update-ca-certificates \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# GPU-accelerated ffmpeg (also needed for opencv)
ENV FFMPEG_VERSION=7.0.1 \
    NVCODEC_VERSION=12.1.14.0
RUN mkdir -p /tmp && chmod 1777 /tmp && \
    apt-get update && \
    apt-get install -y \
    libcrypt-dev \
    autoconf \
    automake \
    build-essential \
    cmake \
    libaom-dev \
    libass-dev \
    libdav1d-dev \
    libdrm-dev \
    libfreetype6-dev \
    libgnutls28-dev \
    libnuma-dev \
    libopenh264-dev \
    libtool \
    libva-dev \
    libvorbis-dev \
    libvpx-dev \
    libwebp-dev \
    pkg-config \
    texinfo \
    vainfo \
    yasm \
    zlib1g-dev && \
    wget -O /tmp/nv-codec-headers.tar.gz https://github.com/FFmpeg/nv-codec-headers/releases/download/n${NVCODEC_VERSION}/nv-codec-headers-${NVCODEC_VERSION}.tar.gz && \
    tar xzvf /tmp/nv-codec-headers.tar.gz -C /tmp/ && \
    cd /tmp/nv-codec-headers-${NVCODEC_VERSION} && \
    make && \
    make install && \
    wget -O /tmp/ffmpeg-snapshot.tar.bz2 https://www.ffmpeg.org/releases/ffmpeg-${FFMPEG_VERSION}.tar.bz2 && \
    tar xjvf /tmp/ffmpeg-snapshot.tar.bz2 -C /tmp/ && \
    cd /tmp/ffmpeg-${FFMPEG_VERSION} && \
    PATH="/usr/local/cuda/bin:$PATH" \
    ./configure \
    --prefix=/usr/local \
    --enable-nonfree \
    --enable-cuda-nvcc \
    --enable-libnpp \
    --enable-libopenh264 \
    --enable-libaom \
    --enable-libdav1d \
    --enable-libvorbis \
    --enable-libvpx \
    --enable-libwebp \
    --enable-vaapi \
    --extra-cflags=-I/usr/local/cuda/include \
    --extra-ldflags=-L/usr/local/cuda/lib64 \
    --extra-libs=-lpthread \
    --extra-libs=-lm \
    --disable-static \
    --enable-shared \
    --disable-doc \
    --disable-debug && \
    make -j$(nproc) && \
    make install && \
    ldconfig && \
    # Clean up
    cd / && \
    rm -rf /tmp/ffmpeg* && \
    rm -rf /tmp/nv-codec-headers* && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Install pixi
RUN wget -qO- https://pixi.sh/install.sh | PIXI_HOME=/usr/local PIXI_NO_PATH_UPDATE=1 sh

# Common ENV variables needed by some ML libs
ENV AM_I_DOCKER=True \
    BUILD_WITH_CUDA=True \
    TORCH_CUDA_ARCH_LIST="5.0;6.0;6.1;7.0;7.5;8.0;8.6;9.0+PTX" \
    CUDA_HOME="/usr/local/cuda"

# Disable Ray log dedup
ENV RAY_DEDUP_LOGS=0 \
    RAY_EXPERIMENTAL_NOSET_CUDA_VISIBLE_DEVICES=1 \
    RAY_MAX_LIMIT_FROM_API_SERVER=40000 \
    RAY_MAX_LIMIT_FROM_DATA_SOURCE=40000 \
    RAY_DEFAULT_OBJECT_STORE_MAX_MEMORY_BYTES=800000000000 \
    RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION=0.4 \
    RAY_gcs_rpc_server_connect_timeout_s=30 \
    RAY_gcs_rpc_server_reconnect_timeout_s=180 \
    XENNA_RAY_METRICS_PORT=9002

# boto3 & pbss
ENV AWS_REQUEST_CHECKSUM_CALCULATION='when_required'

# Set a bunch of env vars so that we cache weights in a workspace
ENV DEFAULT_WORKSPACE_LOC="/config/default_workspace"
ENV HF_HOME="${DEFAULT_WORKSPACE_LOC}/weights/hf_home/" \
    LAION_CACHE_HOME="${DEFAULT_WORKSPACE_LOC}/weights/laion_cache/"

# Set up pixi environments
COPY pixi.toml pixi.lock {{code_dir_str}}/
# If we install all the environments in a single layer, it's over 20GB and will cause slurm/NVCF to timeout pulling the
# layer. Since the text-curator environment is large and needs non-overlapping RAPIDS packages, we install it
# separately.
RUN cd {{code_dir_str}} && \
    export CONDA_OVERRIDE_CUDA=12.9.1 && \
    pixi install -e default -e {{ envs | reject('equalto', 'text-curator') | join(' -e ') }} --frozen && \
    pixi clean cache -y

# Install the text-curator environment separately if requested.
{% if 'text-curator' in envs %} \
RUN cd {{code_dir_str}} && \
    export CONDA_OVERRIDE_CUDA=12.9.1 && \
    pixi install -e text-curator --frozen && \
    pixi clean cache -y
{% endif %}

# Run any hacky post-install script for each environment
COPY package/cosmos_curate/envs/ /tmp/cosmos_curate_build_envs
{% for env in envs %}
RUN if [ -f /tmp/cosmos_curate_build_envs/{{ env }}/post_install.sh ]; then \
        cd {{code_dir_str}} && \
        pixi run -e {{ env }} bash /tmp/cosmos_curate_build_envs/{{ env }}/post_install.sh; \
    fi
{% endfor %}

# Copy the video pipeline code
COPY cosmos_curate {{code_dir_str}}/cosmos_curate
COPY cosmos-xenna/cosmos_xenna {{code_dir_str}}/cosmos_xenna
COPY tests {{code_dir_str}}/tests
COPY pytest.ini .coveragerc {{code_dir_str}}/

# Copy additional code paths into the container
{% for code_path in code_paths %}
COPY {{code_path}} {{code_dir_str}}/{{code_path}}
{% endfor %}

# Expose port for FastAPI & Ray
EXPOSE 8000 6379

WORKDIR {{code_dir_str}}

CMD ["pixi", "run", "python", "cosmos_curate/scripts/onto_nvcf.py", "--helm", "False"]
