# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Attrs objects used to represent and store the outputs of the image captions pipeline.

This objects are meant to represent the schemas for this output data. That means schema evolution needs to be
considered.
"""

import pickle
from typing import Any

import attrs
import cattrs

from cosmos_curate.core.utils.dataset_utils import webdataset_utils
from cosmos_curate.core.utils.dataset_utils.dimensions import Dimensions


@attrs.define
class Debug:
    """The captions generated by this pipeline.

    All captions are guranteed to be filled in, although if "had_parse_issue" is set to true, the pipeline failed to
    parse some of the LLM outputs properly. This may indicate that the "fidelity" caption is not trustworthy and may
    contain some junk from the llm output. In these cases, falling back to the kosmos2 caption may be appropriate.

    The output of the pipeline is stored in the "fidelity" field. The corresponds to the output of step 3.
    """

    gemmma_prompt: str
    llava_num_tokens_in: int
    llava_num_tokens_out: int


@attrs.define
class Captions:
    """The captions generated by this pipeline.

    All captions are guranteed to be filled in, although if "had_parse_issue" is set to true, the pipeline failed to
    parse some of the LLM outputs properly. This may indicate that the "fidelity" caption is not trustworthy and may
    contain some junk from the llm output. In these cases, falling back to the kosmos2 caption may be appropriate.

    The output of the pipeline is stored in the "fidelity" field. The corresponds to the output of step 3.
    """

    kosmos_2: str
    llava: str
    vfc: str


@attrs.define
class Sample:
    """A sample which has been annotated by the AI captions v3.0 pipeline.

    This pipeline generates captions using a series of LMMs and one LLM.

    The sample can be converted to/from webdataset sample format via from_webdataset_sample and to_webdataset_sample.
    To convert to webdataset format, we convert this whole class to a dict and then pickle that dict.

    When converted to a dict, this will look something like:
    ```
    {'captions': {'kosmos_2': 'kosmos2_caption',
                 'llava': 'llava_caption',
                 'vfc_fidelity': 'vfc_fidelity_caption'},
    'debug': {'step_0': 'step_0_caption',
             'step_0_parse_issue': False,
             'step_1': ['foo', 'bar'],
             'step_1_parse_issue': False,
             'step_2': {'detections': [], 'summary': {}, 'summary_no_loc': {}},
             'step_3': 'step_3_caption',
             'step_3_parse_issue': False,
             'step_3_remove_list': []},
    'detections': [{'bounding_box': {'h': 0.22, 'w': 0.11, 'x0': 0.2, 'y0': 0.31},
                    'logit': 0.7,
                    'phrase': 'foo'},
                    {'bounding_box': {'h': 0.22, 'w': 0.11, 'x0': 0.2, 'y0': 0.31},
                    'logit': 0.7,
                    'phrase': 'bar'}],
    'had_parse_issue': False,
    'image_resolution': {'height': 512, 'width': 1024},
    'key': '321356156'}
    ```
    """

    # The key for this sample.
    key: str
    # The resolution for the original image.
    image_resolution: Dimensions
    # A flag which indicates if any of the LLM outputs were unable to be properly parsed.
    # See the "Captions" class for more info.
    had_parse_issue: bool
    # The captions generated by this pipeline.
    captions: Captions
    # Debug information. This is not meant to be consumed by downstream pipelines directly. It is mostly here to debug
    # the pipeline itself.
    debug: Debug

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Sample":
        """Convert a dict to a Sample object.

        Args:
            data: The dict to convert.

        Returns:
            The Sample object.

        """
        return cattrs.structure(data, cls)

    def to_dict(self) -> dict[str, Any]:
        """Convert a Sample object to a dict.

        Returns:
            The dict.

        """
        return cattrs.Converter().unstructure(self)  # type: ignore[no-any-return]

    def to_webdataset_sample(self) -> webdataset_utils.RawSample:
        """Convert a Sample object to a webdataset sample.

        Returns:
            The webdataset sample.

        """
        return webdataset_utils.RawSample(self.key, {"pkl": pickle.dumps(self.to_dict())})
